{"name":"Machine learning assignment","tagline":"","body":"<div id=\"header\">\r\n<h1 class=\"title\"><center>\r\nPredicting Quality of Bicep Curls\r\n</center></h1>\r\n</div>\r\n\r\n\r\n<center>\r\n<strong>Introduction</strong>\r\n</center>\r\n\r\n<p align=\"left\">     One thing that people regularly do is quantify how much of a particular activity they do, but they rarely quantify how well they do it. In this project, the goal is to use data from accelerometers on the belt, forearm, arm, and dumbbell of 6 participants to predict whether the participants performed a bicep curl correctly or incorrectly. The model will be evaluated for performance against test sets of data. The training data originates from the paper &quot;Qualitative Activity Recognition of Weight Lifting Exercises&quot;&quot; by Velloso et al., 2013. </p)\r\n\r\n<center>\r\n<strong>Data Preprocessing</strong>\r\n</center>\r\n<p align=\"left\">    The original dataset contains around 160 variables, thus before creating a parsimonious model, the number of variables needed to be reduced. Exploration of the dataset revealed that numerous columns contained &quot;NA&quot; values as well as data that simply summarized other columns e.g., variance of acceleration in the x direction, so these columns were removed. In addition, the first 7 columns of the dataset did not contain information pertinent to the model such as name of the participant and date, so these were removed as well. The final dimensions of the dataset are shown below followed by the names of the variables used in the model. </p>\r\n<pre><code>## [1] 19622    53</code></pre>\r\n<pre><code>##  [1] &quot;roll_belt&quot;            &quot;pitch_belt&quot;           &quot;yaw_belt&quot;            \r\n##  [4] &quot;total_accel_belt&quot;     &quot;gyros_belt_x&quot;         &quot;gyros_belt_y&quot;        \r\n##  [7] &quot;gyros_belt_z&quot;         &quot;accel_belt_x&quot;         &quot;accel_belt_y&quot;        \r\n## [10] &quot;accel_belt_z&quot;         &quot;magnet_belt_x&quot;        &quot;magnet_belt_y&quot;       \r\n## [13] &quot;magnet_belt_z&quot;        &quot;roll_arm&quot;             &quot;pitch_arm&quot;           \r\n## [16] &quot;yaw_arm&quot;              &quot;total_accel_arm&quot;      &quot;gyros_arm_x&quot;         \r\n## [19] &quot;gyros_arm_y&quot;          &quot;gyros_arm_z&quot;          &quot;accel_arm_x&quot;         \r\n## [22] &quot;accel_arm_y&quot;          &quot;accel_arm_z&quot;          &quot;magnet_arm_x&quot;        \r\n## [25] &quot;magnet_arm_y&quot;         &quot;magnet_arm_z&quot;         &quot;roll_dumbbell&quot;       \r\n## [28] &quot;pitch_dumbbell&quot;       &quot;yaw_dumbbell&quot;         &quot;total_accel_dumbbell&quot;\r\n## [31] &quot;gyros_dumbbell_x&quot;     &quot;gyros_dumbbell_y&quot;     &quot;gyros_dumbbell_z&quot;    \r\n## [34] &quot;accel_dumbbell_x&quot;     &quot;accel_dumbbell_y&quot;     &quot;accel_dumbbell_z&quot;    \r\n## [37] &quot;magnet_dumbbell_x&quot;    &quot;magnet_dumbbell_y&quot;    &quot;magnet_dumbbell_z&quot;   \r\n## [40] &quot;roll_forearm&quot;         &quot;pitch_forearm&quot;        &quot;yaw_forearm&quot;         \r\n## [43] &quot;total_accel_forearm&quot;  &quot;gyros_forearm_x&quot;      &quot;gyros_forearm_y&quot;     \r\n## [46] &quot;gyros_forearm_z&quot;      &quot;accel_forearm_x&quot;      &quot;accel_forearm_y&quot;     \r\n## [49] &quot;accel_forearm_z&quot;      &quot;magnet_forearm_x&quot;     &quot;magnet_forearm_y&quot;    \r\n## [52] &quot;magnet_forearm_z&quot;     &quot;classe&quot;</code></pre>\r\n<center>\r\n<strong>Modeling</strong>\r\n</center>\r\n<p align=\"left\">     To predict bicep curl quality, a random forest model was trained on 60% of the data and further cross-validated with the other 40%. To reduce the computation time, cross validation was only conducted 5 times during random forest modeling. This was tweaked by using the  `trainControl` argument within the`train` function which is inside the caret package. </p>\r\n<pre><code>## Random Forest \r\n## \r\n## 11776 samples\r\n##    52 predictor\r\n##     5 classes: 'A', 'B', 'C', 'D', 'E' \r\n## \r\n## No pre-processing\r\n## Resampling: Cross-Validated (5 fold) \r\n## Summary of sample sizes: 9422, 9421, 9421, 9420, 9420 \r\n## Resampling results across tuning parameters:\r\n## \r\n##   mtry  Accuracy   Kappa      Accuracy SD   Kappa SD   \r\n##    2    0.9879416  0.9847452  0.0009775624  0.001236508\r\n##   27    0.9882815  0.9851749  0.0023737859  0.003003774\r\n##   52    0.9817421  0.9769035  0.0025162095  0.003185687\r\n## \r\n## Accuracy was used to select the optimal model using  the largest value.\r\n## The final value used for the model was mtry = 27.</code></pre>\r\n<p align=\"left\">   This random forest model has up to ~98.9% accuracy on the training set. Below, the values for the test set are predicted using the random forest model fit and compared to their actual values using a confusion matrix.</p>\r\n<pre><code>## Confusion Matrix and Statistics\r\n## \r\n##           Reference\r\n## Prediction    A    B    C    D    E\r\n##          A 2226    5    0    0    0\r\n##          B    3 1507    3    0    1\r\n##          C    2    6 1360   14    2\r\n##          D    0    0    5 1271    5\r\n##          E    1    0    0    1 1434\r\n## \r\n## Overall Statistics\r\n##                                           \r\n##                Accuracy : 0.9939          \r\n##                  95% CI : (0.9919, 0.9955)\r\n##     No Information Rate : 0.2845          \r\n##     P-Value [Acc &gt; NIR] : &lt; 2.2e-16       \r\n##                                           \r\n##                   Kappa : 0.9923          \r\n##  Mcnemar's Test P-Value : NA              \r\n## \r\n## Statistics by Class:\r\n## \r\n##                      Class: A Class: B Class: C Class: D Class: E\r\n## Sensitivity            0.9973   0.9928   0.9942   0.9883   0.9945\r\n## Specificity            0.9991   0.9989   0.9963   0.9985   0.9997\r\n## Pos Pred Value         0.9978   0.9954   0.9827   0.9922   0.9986\r\n## Neg Pred Value         0.9989   0.9983   0.9988   0.9977   0.9988\r\n## Prevalence             0.2845   0.1935   0.1744   0.1639   0.1838\r\n## Detection Rate         0.2837   0.1921   0.1733   0.1620   0.1828\r\n## Detection Prevalence   0.2843   0.1930   0.1764   0.1633   0.1830\r\n## Balanced Accuracy      0.9982   0.9958   0.9952   0.9934   0.9971</code></pre>\r\n<p align=\"left\">   Accuracy is very similar on the test set partition and the out of sample error rate for this single test set is &lt;.01%.</p>\r\n<center>\r\n<strong>Conclusion</strong>\r\n</center>\r\n<p align=\"left\">     Using a randomforest model with 53 predictors and 5 within-set cross-validations, an accuracy of ~98.9% was achieved on classifying the type of bicep curl performed on 60% of the data. The model was cross-validated even further by testing it on 40% of the data. It performed even better with ~99.4% accuracy.</p>\r\n\r\n\r\n</div>\r\n\r\n<script>\r\n// add bootstrap table styles to pandoc tables\r\n$(document).ready(function () {\r\n  $('tr.header').parent('thead').parent('table').addClass('table table-condensed');\r\n});\r\n</script>\r\n\r\n<!-- dynamically load mathjax for compatibility with self-contained -->\r\n<script>\r\n  (function () {\r\n    var script = document.createElement(\"script\");\r\n    script.type = \"text/javascript\";\r\n    script.src  = \"https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML\";\r\n    document.getElementsByTagName(\"head\")[0].appendChild(script);\r\n  })();\r\n</script>\r\n\r\n</body>\r\n</html># ","google":"","note":"Don't delete this file! It's used internally to help with page regeneration."}